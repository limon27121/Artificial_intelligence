{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztvrxbve1Jcy",
        "outputId": "0324bf89-9a8a-464d-953d-03c70f3fa14a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation_accuracy = 94.73684210526315\n",
            "Test_accuracy = 100.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "\n",
        "def euclidean_distance(d1, d2):\n",
        "    point1 = np.array(d1)\n",
        "    point1 = point1[0:4]\n",
        "    point2 = np.array(d2)\n",
        "    point2 = point2[0:4]\n",
        "\n",
        "    sum_sq = np.sum(np.square(point1 - point2))\n",
        "    dist = (np.sqrt(sum_sq))\n",
        "    return dist\n",
        "\n",
        "def majority_class(l, k):\n",
        "    l = l[:k]\n",
        "    count_0 = 0\n",
        "    count_1 = 0\n",
        "    count_2 = 0\n",
        "    for f in l:\n",
        "        if f[-1] == 0:\n",
        "            count_0 +=1\n",
        "\n",
        "        elif f[-1] == 1:\n",
        "            count_1 +=1\n",
        "\n",
        "        else:\n",
        "            count_2 +=1  \n",
        "    \n",
        "\n",
        "    if (count_0 > count_1) and (count_0 > count_2):\n",
        "        largest = 0\n",
        "    elif (count_1 > count_0) and (count_1 > count_2):\n",
        "        largest = 1\n",
        "    else:\n",
        "        largest = 2\n",
        "\n",
        "    return largest    \n",
        "\n",
        "\n",
        "\n",
        "data_path = \"iris.csv\"\n",
        "my_data = np.genfromtxt(data_path, delimiter = ',')\n",
        "\n",
        "data = my_data.tolist()\n",
        "\n",
        "np.random.shuffle(data)\n",
        "\n",
        "Train_set = []\n",
        "Val_set = []\n",
        "Test_set = []\n",
        "\n",
        "\n",
        "for S in data:\n",
        "    R = np.random.rand()\n",
        "    if R >= 0 and R <= 0.7:\n",
        "        Train_set.append(S)\n",
        "    elif R > 0.7 and R <= 0.85:\n",
        "        Val_set.append(S)\n",
        "    else:\n",
        "        Test_set.append(S)\n",
        "\n",
        "\n",
        "K = 15\n",
        "num_of_major = 0\n",
        "v_count = 0\n",
        "for V in Val_set:\n",
        "    L_set = []\n",
        "    for T in Train_set:\n",
        "        distance = euclidean_distance(V, T)\n",
        "        temp = [distance, T[-1]] #label\n",
        "\n",
        "        L_set.append(temp)\n",
        "        \n",
        "    \n",
        "    L_set.sort()\n",
        "    majority = majority_class(L_set, K)\n",
        "    \n",
        "    if V[-1] == majority:\n",
        "        num_of_major += 1\n",
        "\n",
        "    v_count += 1\n",
        "\n",
        "validation_accuracy = num_of_major / v_count  *100\n",
        "print(f'Validation_accuracy = {validation_accuracy}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "K = 5\n",
        "num_of_major = 0\n",
        "T_count = 0\n",
        "for V in Test_set:\n",
        "    L_set = []\n",
        "    for T in Train_set:\n",
        "        distance = euclidean_distance(V, T)\n",
        "        temp = [distance, T[-1]] #label\n",
        "\n",
        "        L_set.append(temp)\n",
        "        \n",
        "    \n",
        "    L_set.sort()\n",
        "    majority = majority_class(L_set, K)\n",
        "    \n",
        "    if V[-1] == majority:\n",
        "        num_of_major += 1\n",
        "\n",
        "    T_count += 1\n",
        "\n",
        "Test_accuracy = num_of_major / T_count  *100\n",
        "print(f'Test_accuracy = {Test_accuracy}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w82tvKbZoLso"
      },
      "source": [
        "KNN regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQHivscvoPSP",
        "outputId": "fbda8479-3581-4c67-9623-3aae1331a250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean_Squared_Error = 5106.105580246914\n",
            "Mean_Squared_Error_Test = 3686.1080193236717\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "\n",
        "def euclidean_distance(d1, d2):\n",
        "    point1 = np.array(d1)\n",
        "    point1 = point1[0:4]\n",
        "    point2 = np.array(d2)\n",
        "    point2 = point2[0:4]\n",
        "    \n",
        "    sum_sq = np.sum(np.square(point1 - point2))\n",
        "    dist = (np.sqrt(sum_sq))\n",
        "    return dist\n",
        "\n",
        "def avg(l, k):\n",
        "    l = l[:k]\n",
        "    avg = 0\n",
        "    for i in range(k):\n",
        "        avg += l[i][1]\n",
        "    avg=avg/K\n",
        "    return avg    \n",
        "\n",
        "\n",
        "\n",
        "data_path = \"diabetes.csv\"\n",
        "my_data = np.genfromtxt(data_path, delimiter = ',')\n",
        "\n",
        "data = my_data.tolist()\n",
        "\n",
        "np.random.shuffle(data)\n",
        "\n",
        "Train_set = []\n",
        "Val_set = []\n",
        "Test_set = []\n",
        "\n",
        "\n",
        "for S in data:\n",
        "    R = np.random.rand()\n",
        "    if R >= 0 and R <= 0.7:\n",
        "        Train_set.append(S)\n",
        "    elif R > 0.7 and R <= 0.85:\n",
        "        Val_set.append(S)\n",
        "    else:\n",
        "        Test_set.append(S)\n",
        "\n",
        "\n",
        "K = 15\n",
        "error = 0\n",
        "num_of_major = 0\n",
        "v_count = 0\n",
        "for V in Val_set:\n",
        "    L_set = []\n",
        "    for T in Train_set:\n",
        "        distance = euclidean_distance(V, T)\n",
        "        temp = [distance, T[-1]] #label\n",
        "        L_set.append(temp)\n",
        "    \n",
        "    L_set.sort()\n",
        "    average = avg(L_set, K)    \n",
        "    e = V[-1] - average\n",
        "    error = error + (e*e)\n",
        "    v_count += 1\n",
        "\n",
        "mean_Squared_Error = error / v_count\n",
        "print(f'Mean_Squared_Error = {mean_Squared_Error}')\n",
        "\n",
        "\n",
        "K = 15\n",
        "error = 0\n",
        "num_of_major = 0\n",
        "T_count = 0\n",
        "for V in Test_set :\n",
        "    L_set = []\n",
        "    for T in Train_set:\n",
        "        distance = euclidean_distance(V, T)\n",
        "        temp = [distance, T[-1]] #label\n",
        "        L_set.append(temp)\n",
        "    \n",
        "    L_set.sort()\n",
        "    average = avg(L_set, K)    \n",
        "    e = V[-1] - average\n",
        "    error = error + (e*e)\n",
        "    T_count += 1\n",
        "\n",
        "mean_Squared_Error = error / T_count\n",
        "print(f'Mean_Squared_Error_Test = {mean_Squared_Error}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "KNN Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
